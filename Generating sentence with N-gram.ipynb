{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5FPZdZpzPNx"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "!pip3 install JPype1-py3\n",
        "!pip3 install konlpy\n",
        "!JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk import word_tokenize\n",
        "from nltk import ConditionalFreqDist\n",
        "from nltk.probability import ConditionalProbDist, MLEProbDist\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import codecs\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from konlpy.tag import Okt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scB7RRWfPq90"
      },
      "outputs": [],
      "source": [
        "sentence = \"나는 매일 아침 지하철을 탄다\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdUxG8DlPrCe",
        "outputId": "2bae2544-90cc-489f-aa27-f951a908a8f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['나는', '매일', '아침', '지하철을', '탄다']\n"
          ]
        }
      ],
      "source": [
        "# Tokenize text \n",
        "tokens = word_tokenize(sentence)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK_vRizDPrE3",
        "outputId": "19873fea-febf-4f9c-9124-68b02b29c1b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['나/Noun', '는/Josa', '매일/Noun', '아침/Noun', '지하철/Noun', '을/Josa', '탄다/Verb']\n"
          ]
        }
      ],
      "source": [
        "# Tokenize based on morpheme\n",
        "tagger = Okt()\n",
        "\n",
        "def tokenize(text):\n",
        "\n",
        "  tokens = ['/'.join(t) for t in tagger.pos(text)]\n",
        "  \n",
        "  return tokens\n",
        "\n",
        "tokens = tokenize(sentence)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neT-HF3CP7mF",
        "outputId": "4c32c4f7-4b31-4f49-dc56-a5b0c2b82bcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bigram: \n",
            "('나/Noun', '는/Josa')\n",
            "('는/Josa', '매일/Noun')\n",
            "('매일/Noun', '아침/Noun')\n",
            "('아침/Noun', '지하철/Noun')\n",
            "('지하철/Noun', '을/Josa')\n",
            "('을/Josa', '탄다/Verb')\n",
            "\n",
            "trigram: \n",
            "('나/Noun', '는/Josa', '매일/Noun')\n",
            "('는/Josa', '매일/Noun', '아침/Noun')\n",
            "('매일/Noun', '아침/Noun', '지하철/Noun')\n",
            "('아침/Noun', '지하철/Noun', '을/Josa')\n",
            "('지하철/Noun', '을/Josa', '탄다/Verb')\n"
          ]
        }
      ],
      "source": [
        "# Convert tokens to N-gram\n",
        "bigram = ngrams(tokens, 2)\n",
        "trigram = ngrams(tokens, 3)\n",
        "\n",
        "print(\"bigram: \")\n",
        "for b in bigram:\n",
        "  print(b)\n",
        "\n",
        "print(\"\\ntrigram: \")\n",
        "for t in trigram:\n",
        "  print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbm-DyBRP7qz",
        "outputId": "479e4159-11a7-47e6-c1f4-38c0678abe2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bigrams with padding: \n",
            "('<s>', '나/Noun')\n",
            "('나/Noun', '는/Josa')\n",
            "('는/Josa', '매일/Noun')\n",
            "('매일/Noun', '아침/Noun')\n",
            "('아침/Noun', '지하철/Noun')\n",
            "('지하철/Noun', '을/Josa')\n",
            "('을/Josa', '탄다/Verb')\n",
            "('탄다/Verb', '</s>')\n"
          ]
        }
      ],
      "source": [
        "# Add tokens indicating the beginning and end of sentences through Padding\n",
        "bigram = ngrams(tokens, 2, pad_left = True, pad_right = True, left_pad_symbol = \"<s>\", right_pad_symbol = \"</s>\")\n",
        "\n",
        "print(\"bigrams with padding: \")\n",
        "for b in bigram:\n",
        "  print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3lRKaTCP7tK",
        "outputId": "e4a6aafd-a3b7-4653-c019-cd0401f1502f"
      },
      "outputs": [],
      "source": [
        "# Download the 'Naver' movie review dataset\n",
        "%%time\n",
        "!wget -nc -q https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOFOrPgQP7vr",
        "outputId": "f99f1e71-8c57-412b-fcef-5dda904009c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터셋:  [['9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0'], ['3819312', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1'], ['10265843', '너무재밓었다그래서보는것을추천한다', '0'], ['9045019', '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', '0'], ['6483659', '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다', '1'], ['5403919', '막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.', '0'], ['7797314', '원작의 긴장감을 제대로 살려내지못했다.', '0'], ['9443947', '별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네', '0'], ['7156791', '액션이 없는데도 재미 있는 몇안되는 영화', '1'], ['5912145', '왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?', '1']]\n",
            "\n",
            "텍스트 데이터: ['아 더빙.. 진짜 짜증나네요 목소리', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '너무재밓었다그래서보는것을추천한다', '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다']\n",
            "\n",
            "문장 개수:  149999\n"
          ]
        }
      ],
      "source": [
        "# Extract the text from the downloaded dataset\n",
        "with codecs.open(\"ratings_train.txt\", encoding='utf-8') as f:\n",
        "  data = [line.split('\\t') for line in f.read().splitlines()]\n",
        "  data = data[1:150000]\n",
        "\n",
        "print(\"데이터셋: \", data[:10])\n",
        "docs = [row[1] for row in data]\n",
        "print(\"\\n텍스트 데이터: \", docs[:5])\n",
        "print(\"\\n문장 개수: \", len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE7QOGiwP7xc",
        "outputId": "580c3c2b-c18a-422b-83cf-9efb37d4f29e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 149999/149999 [05:51<00:00, 427.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('<s>', '아/Exclamation'), ('아/Exclamation', '더빙/Noun'), ('더빙/Noun', '../Punctuation'), ('../Punctuation', '진짜/Noun'), ('진짜/Noun', '짜증나네요/Adjective'), ('짜증나네요/Adjective', '목소리/Noun'), ('목소리/Noun', '</s>'), ('<s>', '흠/Noun'), ('흠/Noun', '.../Punctuation'), ('.../Punctuation', '포스터/Noun')]\n",
            "[('정말/Noun', 2718), ('이/Noun', 2371), ('진짜/Noun', 2232), ('이/Determiner', 2115), ('영화/Noun', 2069)]\n"
          ]
        }
      ],
      "source": [
        "# Add bigram of tokenized text to list\n",
        "sentences = []\n",
        "\n",
        "for d in tqdm(docs):\n",
        "  tokens = tokenize(d)\n",
        "  bigram = ngrams(tokens, 2, pad_left = True, pad_right = True, left_pad_symbol = \"<s>\", right_pad_symbol = \"</s>\")\n",
        "  sentences += [t for t in bigram]\n",
        "\n",
        "print(sentences[:10])\n",
        "\n",
        "cfd = ConditionalFreqDist(sentences)\n",
        "print(cfd[\"<s>\"].most_common(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZD8yc8NQK4Z",
        "outputId": "fb63712e-106a-4e04-8b18-da1bca2969bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('는/Josa', 831), ('의/Josa', 339), ('만/Josa', 213), ('에게/Josa', 148), ('에겐/Josa', 84), ('랑/Josa', 81), ('한테/Josa', 50), ('참/Verb', 45), ('이/Determiner', 44), ('와도/Josa', 43)]\n"
          ]
        }
      ],
      "source": [
        "# Function that returns the n most frequent words following a given token\n",
        "def most_common(c, n, pos = None):\n",
        "  \n",
        "  if pos is None:\n",
        "    return cfd[tokenize(c)[0]].most_common(n)\n",
        "  else:\n",
        "    return cfd[\"/\".join([c, pos])].most_common(n)\n",
        "\n",
        "print(most_common(\"나\", 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbvX__aFQP5v",
        "outputId": "fb1cb660-6782-4179-ec0a-ec36a7a948c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.39102658679807606\n"
          ]
        }
      ],
      "source": [
        "# Estimating conditional probability based on the frequency of occurrence\n",
        "cpd = ConditionalProbDist(cfd, MLEProbDist)\n",
        "print(cpd[tokenize(\".\")[0]].prob(\"</s>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJYqob_-QP8J",
        "outputId": "6bdca758-f599-4633-fbbb-eca447051b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.4010748656417948\n",
            "0.0001576820735192668\n"
          ]
        }
      ],
      "source": [
        "# Calculate the probability that token (w) appears together in a bigram after token (c)\n",
        "def bigram_prob(c, w):\n",
        "\n",
        "  context = tokenize(c)[0]\n",
        "  word = tokenize(w)[0]\n",
        "  \n",
        "  return cpd[context].prob(word)\n",
        "\n",
        "print(bigram_prob(\"이\", \"영화\"))\n",
        "print(bigram_prob(\"영화\", \"이\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yMMxDPgrQP-Q",
        "outputId": "5572aab5-830b-40e4-b243-c11df1d0a505"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "도리까지 본 영화 너무... 뭔가.. 최고네요. 하지만.. 눈물 낫다는건 또 영화에 들지 않는다. 근데 뭐야 어떻게 그렇게 착했던 윤재랑은 에바 그린 드레스 소리 듣는거임\"\"\" 에리 욧의 미모로 번돈으로 그렸으면 좋았을듯, 예전부터 제작비로 흥미진진. 거기 나오는 노래 완전 망쳐 버리네 미친 듯 최고의 얼굴을 뒤엎을 빌렸을 뿐 작품중이 보내는 클라스가 현재 한국에 가장 재미없었다.....................\n",
            "도리/Noun\n",
            "까지/Josa\n",
            "본/Verb\n",
            "영화/Noun\n",
            "너무/Adverb\n",
            ".../Punctuation\n",
            "뭔가/Noun\n",
            "../Punctuation\n",
            "최고/Noun\n",
            "네/Suffix\n",
            "요/Josa\n",
            "./Punctuation\n",
            "하지만/Conjunction\n",
            "../Punctuation\n",
            "눈물/Noun\n",
            "낫다는건/Verb\n",
            "또/Noun\n",
            "영화/Noun\n",
            "에/Josa\n",
            "들지/Verb\n",
            "않는다/Verb\n",
            "./Punctuation\n",
            "근데/Adverb\n",
            "뭐/Noun\n",
            "야/Josa\n",
            "어떻게/Adjective\n",
            "그렇게/Adverb\n",
            "착했던/Adjective\n",
            "윤재/Noun\n",
            "랑은/Josa\n",
            "에바/Noun\n",
            "그린/Noun\n",
            "드레스/Noun\n",
            "소리/Noun\n",
            "듣는거/Verb\n",
            "임/Noun\n",
            "\"\"\"/Punctuation\n",
            "에리/Noun\n",
            "욧의/Noun\n",
            "미모/Noun\n",
            "로/Josa\n",
            "번돈/Noun\n",
            "으로/Josa\n",
            "그렸으면/Verb\n",
            "좋았을듯/Adjective\n",
            ",/Punctuation\n",
            "예전/Noun\n",
            "부터/Josa\n",
            "제작비/Noun\n",
            "로/Josa\n",
            "흥미진진/Noun\n",
            "./Punctuation\n",
            "거기/Noun\n",
            "나오는/Verb\n",
            "노래/Noun\n",
            "완전/Noun\n",
            "망쳐/Verb\n",
            "버리네/Verb\n",
            "미친/Adjective\n",
            "듯/Noun\n",
            "최고/Noun\n",
            "의/Josa\n",
            "얼굴/Noun\n",
            "을/Josa\n",
            "뒤엎/Noun\n",
            "을/Josa\n",
            "빌렸을/Verb\n",
            "뿐/Noun\n",
            "작품/Noun\n",
            "중/Suffix\n",
            "이/Josa\n",
            "보내는/Verb\n",
            "클라스/Noun\n",
            "가/Josa\n",
            "현재/Noun\n",
            "한국/Noun\n",
            "에/Josa\n",
            "가장/Noun\n",
            "재미없었다/Adjective\n",
            "...................../Punctuation\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'도리까지 본 영화 너무... 뭔가.. 최고네요. 하지만.. 눈물 낫다는건 또 영화에 들지 않는다. 근데 뭐야 어떻게 그렇게 착했던 윤재랑은 에바 그린 드레스 소리 듣는거임\"\"\" 에리 욧의 미모로 번돈으로 그렸으면 좋았을듯, 예전부터 제작비로 흥미진진. 거기 나오는 노래 완전 망쳐 버리네 미친 듯 최고의 얼굴을 뒤엎을 빌렸을 뿐 작품중이 보내는 클라스가 현재 한국에 가장 재미없었다.....................'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate a sentence based on the probability\n",
        "def generate_sentence(seed = None, debug = False):\n",
        "\n",
        "  if seed is not None:\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "\n",
        "  c = \"<s>\"\n",
        "  sentence = []\n",
        "  \n",
        "  while True:\n",
        "    if c not in cpd:\n",
        "      break\n",
        "    \n",
        "    w = cpd[c].generate()\n",
        "\n",
        "    if w == \"</s>\":\n",
        "      break\n",
        "\n",
        "    word = w.split(\"/\")[0]\n",
        "    pos = w.split(\"/\")[1]\n",
        "\n",
        "    if c == \"<s>\":\n",
        "      sentence.append(word.title())\n",
        "    elif c in [\"`\", \"\\\"\",\"'\",\"(\"]:\n",
        "      sentence.append(word)\n",
        "    elif word in [\"'\", \".\", \",\", \")\", \":\", \";\", \"?\"]:\n",
        "      sentence.append(word)\n",
        "    elif pos in [\"Josa\", \"Punctuation\", \"Suffix\"]:\n",
        "        sentence.append(word)\n",
        "    elif w in [\"임/Noun\", \"것/Noun\", \"는걸/Noun\", \"릴때/Noun\",\n",
        "                \"되다/Verb\", \"이다/Verb\", \"하다/Verb\", \"이다/Adjective\"]:\n",
        "        sentence.append(word)\n",
        "    else:\n",
        "        sentence.append(\" \" + word)\n",
        "    c = w\n",
        "\n",
        "    if debug:\n",
        "      print(w)\n",
        "\n",
        "  return \"\".join(sentence)\n",
        "\n",
        "\n",
        "print(generate_sentence(2))\n",
        "\n",
        "generate_sentence(2, debug = True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
